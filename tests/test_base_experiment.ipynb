{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95cac579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(\n",
    "    os.path.join(os.path.dirname('__file__'), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51834613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3e194c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.encoding.encoders import *\n",
    "from src.encoding.tools import create_encoding_pipeline\n",
    "from src.models.sklearn_models import save_object, Model\n",
    "from src.models.sklearn_models_config import get_model\n",
    "from src.datasets.base_tabular_dataset import BaseTabularDataset\n",
    "from src.experiments.base_experiment import BaseExperiment\n",
    "import src.features as ft\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9706ae",
   "metadata": {},
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "992a7f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.basicConfig(level=logging.INFO, encoding=\"utf-8\",\n",
    "                    format=\"%(asctime)s: %(levelname)s: %(message)s\",\n",
    "                    datefmt='%Y/%m/%d %H:%M:%S',\n",
    "                    handlers=[logging.StreamHandler()])\n",
    "root_dir = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..'))\n",
    "config = ft.Config({'max_nan': 15, \"departement\": \"21\", \"root_dir\": root_dir, \"start\": '01-01-2019',\n",
    "                    \"stop\": '31-12-2023', \"logger\": logger, \"step_unit\": 'days', \"step_value\": 1,\n",
    "                    \"shift\": 0, \"rolling_window\": 0, \"etablissement\": \"CHU Dijon\", 'region':'BOURGOGNE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a21bd581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/13 18:15:03: INFO: Initialisation de la classe HopitalFeatures\n",
      "2024/09/13 18:15:03: INFO: Initialisation de la classe FireFightersFeatures\n"
     ]
    }
   ],
   "source": [
    "ars_features_class = [ft.AirQualityFeatures, ft.HopitalFeatures(config=config, include_emmergency_arrivals=True, include_nb_hospit=True), ft.EpidemiologicalFeatures, ft.FireFightersFeatures(config=config, include_calls=False),\n",
    "                      ft.GoogleTrendFeatures, ft.MeteorologicalFeatures, ft.SociologicalFeatures,\n",
    "                      ft.SportsCompetitionFeatures, ft.TrafficFeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c2f2b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/13 18:15:03: INFO: Initialisation de la classe BaseTabularDataset_Total_CHU Dijon\n",
      "2024/09/13 18:15:03: INFO: Initialisation de la classe AirQualityFeatures\n",
      "2024/09/13 18:15:03: INFO: Initialisation de la classe EpidemiologicalFeatures\n",
      "2024/09/13 18:15:03: INFO: Initialisation de la classe GoogleTrendFeatures\n",
      "2024/09/13 18:15:03: INFO: Initialisation de la classe MeteorologicalFeatures\n",
      "2024/09/13 18:15:03: INFO: Initialisation de la classe SociologicalFeatures\n",
      "2024/09/13 18:15:03: INFO: Initialisation de la classe SportsCompetitionFeatures\n",
      "2024/09/13 18:15:03: INFO: Initialisation de la classe TrafficFeatures\n",
      "2024/09/13 18:15:03: INFO: Fetching data for BaseTabularDataset_Total_CHU Dijon...\n",
      "2024/09/13 18:15:03: INFO: Fetching data from AirQualityFeatures({'max_nan': 15, 'departement': '21', 'root_dir': '/home/maxime/Documents/WORKSPACES/forecasting_models', 'start': '01-01-2019', 'stop': '31-12-2023', 'logger': <RootLogger root (INFO)>, 'step_unit': 'days', 'step_value': 1, 'shift': 0, 'rolling_window': 0, 'etablissement': 'CHU Dijon', 'region': 'BOURGOGNE'})\n",
      "2024/09/13 18:15:03: INFO: Fetching data for AirQualityFeatures...\n",
      "2024/09/13 18:15:03: INFO: On regarde la qualit√© de l'air\n",
      "2024/09/13 18:15:03: INFO: On s'int√©resse aux codes : FR26005, FR26010, FR26014, FR26094\n",
      "2024/09/13 18:15:03: INFO: On relit le dataframe d'archive de l'air\n",
      "2024/09/13 18:15:03: INFO: Fin de la gestion de la qualit√© de l'air en 0.01 s.\n",
      "2024/09/13 18:15:03: INFO: Saving data for AirQualityFeatures...\n",
      "2024/09/13 18:15:03: INFO: Fetching data from HopitalFeatures({'max_nan': 15, 'departement': '21', 'root_dir': '/home/maxime/Documents/WORKSPACES/forecasting_models', 'start': '01-01-2019', 'stop': '31-12-2023', 'logger': <RootLogger root (INFO)>, 'step_unit': 'days', 'step_value': 1, 'shift': 0, 'rolling_window': 0, 'etablissement': 'CHU Dijon', 'region': 'BOURGOGNE'})\n",
      "2024/09/13 18:15:03: INFO: Fetching data for HopitalFeatures...\n",
      "2024/09/13 18:15:03: INFO: Int√©gration de la target\n",
      "2024/09/13 18:15:03: INFO:   - Chargement des donn√©es de CHU Dijon depuis le fichier Excel\n",
      "2024/09/13 18:15:03: INFO: Int√©gration du d√©m√©nagement de l'HNFC\n",
      "2024/09/13 18:15:03: INFO: Saving data for HopitalFeatures...\n",
      "2024/09/13 18:15:03: INFO: Fetching data from EpidemiologicalFeatures({'max_nan': 15, 'departement': '21', 'root_dir': '/home/maxime/Documents/WORKSPACES/forecasting_models', 'start': '01-01-2019', 'stop': '31-12-2023', 'logger': <RootLogger root (INFO)>, 'step_unit': 'days', 'step_value': 1, 'shift': 0, 'rolling_window': 0, 'etablissement': 'CHU Dijon', 'region': 'BOURGOGNE'})\n",
      "2024/09/13 18:15:03: INFO: Fetching data for EpidemiologicalFeatures...\n",
      "2024/09/13 18:15:03: INFO: On s'occupe de l'incidence des maladies d'apr√®s Sentinelles\n",
      "2024/09/13 18:15:03: INFO:   - on regarde l'incidence de grippe pour la r√©gion BOURGOGNE\n",
      "2024/09/13 18:15:03: INFO: Chargement du mod√®le de pr√©diction pour grippe\n",
      "2024/09/13 18:15:04: INFO: Mod√®le grippe charg√©\n",
      "2024/09/13 18:15:04: INFO:     Pour la derni√®re date connue ('02/09/2024', semaine 202436), l'incidence √©tait de 757\n",
      "2024/09/13 18:15:04: INFO:     La premi√®re date connue √©tait '29/10/1984', semaine 198444\n",
      "2024/09/13 18:15:04: INFO:   - on regarde l'incidence de diarrhee pour la r√©gion BOURGOGNE\n",
      "2024/09/13 18:15:04: INFO: Chargement du mod√®le de pr√©diction pour diarrhee\n",
      "2024/09/13 18:15:05: INFO: Mod√®le diarrhee charg√©\n",
      "2024/09/13 18:15:05: INFO:     Pour la derni√®re date connue ('02/09/2024', semaine 202436), l'incidence √©tait de 822\n",
      "2024/09/13 18:15:05: INFO:     La premi√®re date connue √©tait '03/12/1990', semaine 199049\n",
      "2024/09/13 18:15:05: INFO:   - on regarde l'incidence de varicelle pour la r√©gion BOURGOGNE\n",
      "2024/09/13 18:15:05: INFO: Chargement du mod√®le de pr√©diction pour varicelle\n",
      "2024/09/13 18:15:06: INFO: Mod√®le varicelle charg√©\n",
      "2024/09/13 18:15:06: INFO:     Pour la derni√®re date connue ('02/09/2024', semaine 202436), l'incidence √©tait de 214\n",
      "2024/09/13 18:15:06: INFO:     La premi√®re date connue √©tait '03/12/1990', semaine 199049\n",
      "2024/09/13 18:15:06: INFO:   - on regarde l'incidence de ira pour la r√©gion BOURGOGNE\n",
      "2024/09/13 18:15:06: INFO: Chargement du mod√®le de pr√©diction pour ira\n",
      "2024/09/13 18:15:06: INFO: Mod√®le ira charg√©\n",
      "2024/09/13 18:15:06: INFO:     Pour la derni√®re date connue ('02/09/2024', semaine 202436), l'incidence √©tait de 1573\n",
      "2024/09/13 18:15:06: INFO:     La premi√®re date connue √©tait '23/03/2020', semaine 202012\n",
      "2024/09/13 18:15:06: INFO:     Cette premi√®re date √©tant post√©rieure, √† notre historique (commen√ßant le '01/01/2019'), on compl√®te les incidences par des 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 202012 ('16/03/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 202011 ('09/03/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 202010 ('02/03/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 202009 ('24/02/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 202008 ('17/02/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 202007 ('10/02/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 202006 ('03/02/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 202005 ('27/01/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 202004 ('20/01/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 202003 ('13/01/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 202002 ('06/01/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 202001 ('30/12/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201952 ('23/12/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201951 ('16/12/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201950 ('09/12/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201949 ('02/12/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201948 ('25/11/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201947 ('18/11/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201946 ('11/11/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201945 ('04/11/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201944 ('28/10/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201943 ('21/10/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201942 ('14/10/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201941 ('07/10/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201940 ('30/09/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201939 ('23/09/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201938 ('16/09/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201937 ('09/09/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201936 ('02/09/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201935 ('26/08/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201934 ('19/08/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201933 ('12/08/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201932 ('05/08/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201931 ('29/07/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201930 ('22/07/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201929 ('15/07/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201928 ('08/07/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201927 ('01/07/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201926 ('24/06/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201925 ('17/06/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201924 ('10/06/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201923 ('03/06/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201922 ('27/05/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201921 ('20/05/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201920 ('13/05/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201919 ('06/05/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201918 ('29/04/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201917 ('22/04/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201916 ('15/04/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201915 ('08/04/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201914 ('01/04/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201913 ('25/03/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201912 ('18/03/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201911 ('11/03/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201910 ('04/03/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201909 ('25/02/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201908 ('18/02/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201907 ('11/02/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201906 ('04/02/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201905 ('28/01/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201904 ('21/01/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201903 ('14/01/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201902 ('07/01/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On compl√®te la semaine 201901 ('31/12/2018') par 0\n",
      "2024/09/13 18:15:06: INFO: Donn√©es sentinelles int√©gralement r√©cup√©r√©es\n",
      "2024/09/13 18:15:07: INFO: Saving data for EpidemiologicalFeatures...\n",
      "2024/09/13 18:15:07: INFO: Fetching data from FireFightersFeatures({'max_nan': 15, 'departement': '21', 'root_dir': '/home/maxime/Documents/WORKSPACES/forecasting_models', 'start': '01-01-2019', 'stop': '31-12-2023', 'logger': <RootLogger root (INFO)>, 'step_unit': 'days', 'step_value': 1, 'shift': 0, 'rolling_window': 0, 'etablissement': 'CHU Dijon', 'region': 'BOURGOGNE'})\n",
      "2024/09/13 18:15:07: INFO: Fetching data for FireFightersFeatures...\n",
      "2024/09/13 18:15:07: INFO: Saving data for FireFightersFeatures...\n",
      "2024/09/13 18:15:07: INFO: Fetching data from GoogleTrendFeatures({'max_nan': 15, 'departement': '21', 'root_dir': '/home/maxime/Documents/WORKSPACES/forecasting_models', 'start': '01-01-2019', 'stop': '31-12-2023', 'logger': <RootLogger root (INFO)>, 'step_unit': 'days', 'step_value': 1, 'shift': 0, 'rolling_window': 0, 'etablissement': 'CHU Dijon', 'region': 'BOURGOGNE'})\n",
      "2024/09/13 18:15:07: INFO: Fetching data for GoogleTrendFeatures...\n",
      "2024/09/13 18:15:07: INFO: On r√©cup√®re les donn√©es de Google Trends\n",
      "2024/09/13 18:15:07: INFO: On charge les donn√©es de Google Trends depuis le fichier\n",
      "2024/09/13 18:15:07: INFO: Donn√©es de Google Trends int√©gr√©es\n",
      "2024/09/13 18:15:07: INFO: Saving data for GoogleTrendFeatures...\n",
      "2024/09/13 18:15:07: INFO: Fetching data from MeteorologicalFeatures({'max_nan': 15, 'departement': '21', 'root_dir': '/home/maxime/Documents/WORKSPACES/forecasting_models', 'start': '01-01-2019', 'stop': '31-12-2023', 'logger': <RootLogger root (INFO)>, 'step_unit': 'days', 'step_value': 1, 'shift': 0, 'rolling_window': 0, 'etablissement': 'CHU Dijon', 'region': 'BOURGOGNE'})\n",
      "2024/09/13 18:15:07: INFO: Fetching data for MeteorologicalFeatures...\n",
      "2024/09/13 18:15:07: INFO: On r√©cup√®re les archives Meteostat\n",
      "FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "2024/09/13 18:15:07: INFO: Saving data for MeteorologicalFeatures...\n",
      "2024/09/13 18:15:07: INFO: Fetching data from SociologicalFeatures({'max_nan': 15, 'departement': '21', 'root_dir': '/home/maxime/Documents/WORKSPACES/forecasting_models', 'start': '01-01-2019', 'stop': '31-12-2023', 'logger': <RootLogger root (INFO)>, 'step_unit': 'days', 'step_value': 1, 'shift': 0, 'rolling_window': 0, 'etablissement': 'CHU Dijon', 'region': 'BOURGOGNE'})\n",
      "2024/09/13 18:15:07: INFO: Fetching data for SociologicalFeatures...\n",
      "2024/09/13 18:15:07: INFO: On s'occupe des variables de vacances\n",
      "2024/09/13 18:15:07: INFO: On r√©cup√®re la liste des jours f√©ri√©s\n",
      "2024/09/13 18:15:07: INFO: On l'int√®gre au dataframe\n",
      "2024/09/13 18:15:07: INFO: On s'occupe des vacances en tant que tel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dijon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/13 18:15:07: INFO: Variables de vacances int√©gr√©es\n",
      "2024/09/13 18:15:07: INFO: On s'occupe des variables de confinement\n",
      "2024/09/13 18:15:07: INFO: Variables de confinement int√©gr√©es\n",
      "2024/09/13 18:15:07: INFO: On s'occupe des variables de Ramadan\n",
      "2024/09/13 18:15:07: INFO: Saving data for SociologicalFeatures...\n",
      "2024/09/13 18:15:07: INFO: Fetching data from SportsCompetitionFeatures({'max_nan': 15, 'departement': '21', 'root_dir': '/home/maxime/Documents/WORKSPACES/forecasting_models', 'start': '01-01-2019', 'stop': '31-12-2023', 'logger': <RootLogger root (INFO)>, 'step_unit': 'days', 'step_value': 1, 'shift': 0, 'rolling_window': 0, 'etablissement': 'CHU Dijon', 'region': 'BOURGOGNE'})\n",
      "2024/09/13 18:15:07: INFO: Fetching data for SportsCompetitionFeatures...\n",
      "2024/09/13 18:15:07: INFO: Int√©gration des donn√©es de football\n",
      "2024/09/13 18:15:07: INFO: Donn√©es de football int√©gr√©es\n",
      "2024/09/13 18:15:07: INFO: Saving data for SportsCompetitionFeatures...\n",
      "2024/09/13 18:15:07: INFO: Fetching data from TrafficFeatures({'max_nan': 15, 'departement': '21', 'root_dir': '/home/maxime/Documents/WORKSPACES/forecasting_models', 'start': '01-01-2019', 'stop': '31-12-2023', 'logger': <RootLogger root (INFO)>, 'step_unit': 'days', 'step_value': 1, 'shift': 0, 'rolling_window': 0, 'etablissement': 'CHU Dijon', 'region': 'BOURGOGNE'})\n",
      "2024/09/13 18:15:07: INFO: Fetching data for TrafficFeatures...\n",
      "2024/09/13 18:15:07: INFO: Int√©gration des donn√©es de trafic\n",
      "FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "2024/09/13 18:15:08: INFO: Saving data for TrafficFeatures...\n",
      "2024/09/13 18:15:08: INFO: Saving data for BaseTabularDataset_Total_CHU Dijon...\n"
     ]
    }
   ],
   "source": [
    "arsTabularDataset = BaseTabularDataset(target_colomns=['Total_CHU Dijon'],  # ,  'nb_vers_hospit'\n",
    "                                       config=config, features_class=ars_features_class)\n",
    "arsTabularDataset.fetch_data(save=True) # Fetch data from the features, do this only once, if you need smaller datasets, use the get_dataset method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbf79c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'early_stopping_rounds': 10,\n",
    "    # 'eval_set': [(arsTabularDataset.enc_X_val, arsTabularDataset.y_val)], # TODO: to be set in the experiment's run method\n",
    "    'verbosity': 0,\n",
    "    'n_estimators': 10000,\n",
    "    'learning_rate': 0.1,\n",
    "    'min_child_weight': 5,\n",
    "    # 'multi_strategy': 'one_output_per_tree',\n",
    "    # 'multi_strategy': 'multi_output_tree' \n",
    "}\n",
    "model = get_model(model_type='xgboost', name='XGBRegressor', device='cuda', task_type='regression', test_metrics='rmse', with_metric='w_rmse', params=model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25abf121",
   "metadata": {},
   "outputs": [],
   "source": [
    "ars_experiment = BaseExperiment(dataset=arsTabularDataset, model=model, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98c2c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    'max_depth': [3, 5, 7, 9, 11],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddc6873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {\n",
    "    'verbose': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c4f4ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders_dict = {\n",
    "    'number': {\n",
    "        'as_number': {\n",
    "            'imputers': [imputers.SimpleImputer(strategy='mean')],\n",
    "            'encoders': [\n",
    "                ne.StandardScaler(),\n",
    "\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    'category': {\n",
    "        'as_category': {\n",
    "            'imputers': [imputers.SimpleImputer(strategy='most_frequent')],\n",
    "            'encoders': [\n",
    "                # ne.TargetEncoder(target_type='continuous-multioutput'),\n",
    "                # ne.TargetEncoder(target_type='continuous'),\n",
    "                ne.MultiTargetEncoder(drop_invariant=True, return_df=True),\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    'datetime': {\n",
    "        'as_number': {\n",
    "            'imputers': [de.DateFeatureExtractor()],\n",
    "            'encoders': [\n",
    "                ne.CyclicalFeatures(drop_original=True)\n",
    "            ]\n",
    "        },\n",
    "        'as_category': {\n",
    "            'imputers': [de.DateFeatureExtractor(dtype='category')],\n",
    "            'encoders': [\n",
    "                # ne.TargetEncoder(target_type='continuous'),\n",
    "                ne.MultiTargetEncoder(drop_invariant=True, return_df=True),\n",
    "\n",
    "\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1565c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tes = ne.MultiTargetEncoder(drop_invariant=True, return_df=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b76c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tes.set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c31ece50",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_config = {'test_size': 0.2, 'val_size': 0.2, 'shuffle': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae2016f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating encoding pipeline\n"
     ]
    }
   ],
   "source": [
    "dataset_config={'from_date': '01-01-2019', 'to_date': '31-12-2023', 'shift':7, 'rolling_window':[7, 14], 'freq':'1YE', 'split_config': split_config}\n",
    "model_config={\"optimization\": \"grid\", \"grid_params\": grid_params, \"fit_params\": fit_params}\n",
    "encoding_pipeline = create_encoding_pipeline(encoders_dict=encoders_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ea821d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/13 18:15:08 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "2024/09/13 18:15:08: INFO: Running the experiment...\n",
      "2024/09/13 18:15:08: INFO: Augmentation des features...\n",
      "2024/09/13 18:15:08: INFO: Aggregating data by data type...\n",
      "2024/09/13 18:15:34 INFO mlflow.tracking._tracking_service.client: üèÉ View run run_29 at: http://127.0.0.1:8080/#/experiments/397958626087620787/runs/652073be21ed46a894d0a7a5d78056f3.\n",
      "2024/09/13 18:15:34 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/397958626087620787.\n",
      "2024/09/13 18:15:34 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FeatureUnion]  (step 1 of 4) Processing columntransformer-1, total=   0.1s\n",
      "[FeatureUnion]  (step 2 of 4) Processing columntransformer-2, total=   0.0s\n",
      "[FeatureUnion]  (step 3 of 4) Processing columntransformer-3, total=   0.0s\n",
      "[FeatureUnion]  (step 4 of 4) Processing columntransformer-4, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/13 18:15:34 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "dataset = ars_experiment.run(dataset_config=dataset_config, model_config=model_config, encoding_pipeline=encoding_pipeline, find_best_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ddce312",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ars_experiment.dataset\n",
    "data = dataset.data\n",
    "enc_data = dataset.enc_data\n",
    "train_set = dataset.train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "322a6415",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dataset.X_train\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "438e738c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/13 18:16:30: INFO: Aggregating data by data type...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1YE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_subplots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/forecasting_models/src/features/base_features.py:649\u001b[0m, in \u001b[0;36mBaseFeature.plot\u001b[0;34m(self, from_date, to_date, features_names, freq, max_subplots, data)\u001b[0m\n\u001b[1;32m    646\u001b[0m num_figures \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mceil(num_vars \u001b[38;5;241m/\u001b[39m max_subplots)\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (freq \u001b[38;5;241m!=\u001b[39m pd\u001b[38;5;241m.\u001b[39minfer_freq(data\u001b[38;5;241m.\u001b[39mindex)) \u001b[38;5;129;01mand\u001b[39;00m (freq \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (freq \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m pd\u001b[38;5;241m.\u001b[39minfer_freq(data\u001b[38;5;241m.\u001b[39mindex)) \u001b[38;5;129;01mand\u001b[39;00m (freq \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m pd\u001b[38;5;241m.\u001b[39minfer_freq(data\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (freq \u001b[38;5;241m!=\u001b[39m pd\u001b[38;5;241m.\u001b[39minfer_freq(data\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 649\u001b[0m     agg_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate_data_by_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43magg_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnumber\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mrelative_frequency\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    651\u001b[0m     agg_data \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/forecasting_models/src/features/base_features.py:462\u001b[0m, in \u001b[0;36mBaseFeature.aggregate_data_by_dtype\u001b[0;34m(self, agg_dict, data, freq, flatten)\u001b[0m\n\u001b[1;32m    459\u001b[0m grouped_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby(grouper)\n\u001b[1;32m    461\u001b[0m \u001b[38;5;66;03m# Appliquer les agr√©gations\u001b[39;00m\n\u001b[0;32m--> 462\u001b[0m aggregated_df \u001b[38;5;241m=\u001b[39m \u001b[43mgrouped_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapply_aggregations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(aggregated_df, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m    466\u001b[0m     aggregated_df \u001b[38;5;241m=\u001b[39m aggregated_df\u001b[38;5;241m.\u001b[39mto_frame()\u001b[38;5;241m.\u001b[39munstack(level\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m.\u001b[39mdroplevel(\u001b[38;5;241m0\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1824\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, include_groups, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1822\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1823\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1824\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1825\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1826\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, Series)\n\u001b[1;32m   1827\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1828\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1829\u001b[0m         ):\n\u001b[1;32m   1830\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1831\u001b[0m                 message\u001b[38;5;241m=\u001b[39m_apply_groupings_depr\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1832\u001b[0m                     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1835\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1836\u001b[0m             )\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1885\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m   1852\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1857\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1883\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1885\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_groupwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1886\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1887\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/groupby/ops.py:919\u001b[0m, in \u001b[0;36mBaseGrouper.apply_groupwise\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    918\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 919\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    921\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/forecasting_models/src/features/base_features.py:455\u001b[0m, in \u001b[0;36mBaseFeature.aggregate_data_by_dtype.<locals>.apply_aggregations\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, funcs \u001b[38;5;129;01min\u001b[39;00m column_agg_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;66;03m# print(group[col])\u001b[39;00m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# self.logger.info(f\"Aggregating column {col}...\")\u001b[39;00m\n\u001b[1;32m    453\u001b[0m     aggregated[col] \u001b[38;5;241m=\u001b[39m unified_apply_func(group[col], funcs)\n\u001b[0;32m--> 455\u001b[0m     concat \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43maggregated\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concat\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/reshape/concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/reshape/concat.py:644\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m     new_index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(res))\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     new_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    646\u001b[0m mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(sample\u001b[38;5;241m.\u001b[39m_mgr)\u001b[38;5;241m.\u001b[39mfrom_array(res, index\u001b[38;5;241m=\u001b[39mnew_index)\n\u001b[1;32m    648\u001b[0m result \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(mgr, axes\u001b[38;5;241m=\u001b[39mmgr\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/reshape/concat.py:702\u001b[0m, in \u001b[0;36m_Concatenator.new_axes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_axes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Index]:\n\u001b[1;32m    701\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_result_dim()\n\u001b[0;32m--> 702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concat_axis \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_comb_axis(i)\n\u001b[1;32m    704\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndim)\n\u001b[1;32m    705\u001b[0m     ]\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/reshape/concat.py:703\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_axes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Index]:\n\u001b[1;32m    701\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_result_dim()\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 703\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concat_axis\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_comb_axis(i)\n\u001b[1;32m    704\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndim)\n\u001b[1;32m    705\u001b[0m     ]\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/reshape/concat.py:762\u001b[0m, in \u001b[0;36m_Concatenator._get_concat_axis\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m     concat_axis \u001b[38;5;241m=\u001b[39m _concat_indexes(indexes)\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 762\u001b[0m     concat_axis \u001b[38;5;241m=\u001b[39m \u001b[43m_make_concat_multiindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindexes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_check_integrity(concat_axis)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concat_axis\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/reshape/concat.py:807\u001b[0m, in \u001b[0;36m_make_concat_multiindex\u001b[0;34m(indexes, keys, levels, names)\u001b[0m\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m level\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[1;32m    805\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLevel values not unique: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mall_indexes_same\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexes\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(level\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;28;01mfor\u001b[39;00m level \u001b[38;5;129;01min\u001b[39;00m levels):\n\u001b[1;32m    808\u001b[0m     codes_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;66;03m# things are potentially different sizes, so compute the exact codes\u001b[39;00m\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;66;03m# for each level and pass those to MultiIndex.from_arrays\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/indexes/api.py:383\u001b[0m, in \u001b[0;36mall_indexes_same\u001b[0;34m(indexes)\u001b[0m\n\u001b[1;32m    381\u001b[0m itr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(indexes)\n\u001b[1;32m    382\u001b[0m first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(itr)\n\u001b[0;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfirst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/indexes/api.py:383\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    381\u001b[0m itr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(indexes)\n\u001b[1;32m    382\u001b[0m first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(itr)\n\u001b[0;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43mfirst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m itr)\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:5649\u001b[0m, in \u001b[0;36mIndex.equals\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   5645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype):\n\u001b[1;32m   5646\u001b[0m     \u001b[38;5;66;03m# All EA-backed Index subclasses override equals\u001b[39;00m\n\u001b[1;32m   5647\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m other\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 5649\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_equivalent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/dtypes/missing.py:531\u001b[0m, in \u001b[0;36marray_equivalent\u001b[0;34m(left, right, strict_nan, dtype_equal)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;66;03m# Slow path when we allow comparing different dtypes.\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;66;03m# Object arrays can contain None, NaN and NaT.\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;66;03m# string dtypes must be come to this path for NumPy 1.7.1 compat\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOSU\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m right\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOSU\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;66;03m# Note: `in \"OSU\"` is non-trivially faster than `in [\"O\", \"S\", \"U\"]`\u001b[39;00m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;66;03m#  or `in (\"O\", \"S\", \"U\")`\u001b[39;00m\n\u001b[0;32m--> 531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_equivalent_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# NaNs can occur in float and complex arrays.\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/dtypes/missing.py:576\u001b[0m, in \u001b[0;36m_array_equivalent_object\u001b[0;34m(left, right, strict_nan)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 576\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_equivalent_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39marray_equivalent_object(left[\u001b[38;5;241m~\u001b[39mmask], right[\u001b[38;5;241m~\u001b[39mmask]):\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset.plot(freq='1YE', max_subplots=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc238c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f9e045d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/13 18:15:34: INFO: Augmentation des features...\n",
      "2024/09/13 18:15:35: INFO: Aggregating data by data type...\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.get_dataset(**dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c282f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_data = dataset.enc_data\n",
    "enc_data"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
