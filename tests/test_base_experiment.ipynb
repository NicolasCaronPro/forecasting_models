{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe196b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(\n",
    "    os.path.join(os.path.dirname('__file__'), '..')))\n",
    "from src.encoding.encoders import *\n",
    "from src.encoding.tools import create_encoding_pipeline\n",
    "from src.models.sklearn_models import save_object, Model\n",
    "from src.models.sklearn_models_config import get_model\n",
    "from src.datasets.base_tabular_dataset import BaseTabularDataset\n",
    "from src.experiments.base_experiment import BaseExperiment\n",
    "import src.features as ft\n",
    "import logging\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "700a87e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.basicConfig(level=logging.INFO, encoding=\"utf-8\",\n",
    "                    format=\"%(asctime)s: %(levelname)s: %(message)s\",\n",
    "                    datefmt='%Y/%m/%d %H:%M:%S',\n",
    "                    handlers=[logging.StreamHandler()])\n",
    "root_dir = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..'))\n",
    "config = ft.Config({'max_nan': 15, \"departement\": \"21\", \"root_dir\": root_dir, \"start\": '01-01-2019',\n",
    "                    \"stop\": '31-12-2023', \"logger\": logger, \"step_unit\": 'days', \"step_value\": 1,\n",
    "                    \"shift\": 0, \"rolling_window\": 0, \"etablissement\": \"CHU Dijon\", 'region':'BOURGOGNE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4210d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ars_features_class = [ft.AirQualityFeatures(config=config, drop_const_cols=True), ft.HopitalFeatures(config=config, include_emmergency_arrivals=True, include_nb_hospit=True), ft.EpidemiologicalFeatures, ft.FireFightersFeatures(config=config, include_calls=False),\n",
    "                      ft.GoogleTrendFeatures, ft.MeteorologicalFeatures, ft.SociologicalFeatures,\n",
    "                      ft.SportsCompetitionFeatures, ft.TrafficFeatures]\n",
    "# target_colomns = ['nb_vers_hospit']\n",
    "target_colomns = ['Total_CHU Dijon']\n",
    "arsTabularDataset = BaseTabularDataset(target_colomns=target_colomns,\n",
    "                                       config=config, features_class=ars_features_class)\n",
    "arsTabularDataset.fetch_data(save=False) # Fetch data from the features, do this only once, if you need smaller datasets, use the get_dataset method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "972195b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'early_stopping_rounds': 10,\n",
    "    # 'eval_set': [(arsTabularDataset.enc_X_val, arsTabularDataset.y_val)], # Is set in the experiment's run method\n",
    "    'verbosity': 0,\n",
    "    'n_estimators': 10000,\n",
    "    'learning_rate': 0.1,\n",
    "    'min_child_weight': 5,\n",
    "    # 'multi_strategy': 'one_output_per_tree',\n",
    "    # 'multi_strategy': 'multi_output_tree' \n",
    "}\n",
    "model = get_model(model_type='xgboost', name='XGBRegressor', device='cuda', task_type='regression', test_metrics='w_rmse', with_metric='w_rmse', params=model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef17e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ars_experiment = BaseExperiment(dataset=arsTabularDataset, model=model, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efd99893",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    'max_depth': [3, 5, 7, 9, 11],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49376210",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {\n",
    "    'verbose': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19cad46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders_dict = {\n",
    "    'number': {\n",
    "        'as_number': {\n",
    "            'imputers': [imputers.SimpleImputer(strategy='mean')],\n",
    "            'encoders': [\n",
    "                ne.StandardScaler(),\n",
    "\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    'category': {\n",
    "        'as_category': {\n",
    "            'imputers': [imputers.SimpleImputer(strategy='most_frequent')],\n",
    "            'encoders': [\n",
    "                # ne.TargetEncoder(target_type='continuous-multioutput'),\n",
    "                # ne.TargetEncoder(target_type='continuous'),\n",
    "                ne.MultiTargetEncoder(drop_invariant=True, return_df=True),\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    'datetime': {\n",
    "        'as_number': {\n",
    "            'imputers': [de.DateFeatureExtractor()],\n",
    "            'encoders': [\n",
    "                ne.CyclicalFeatures(drop_original=True)\n",
    "            ]\n",
    "        },\n",
    "        'as_category': {\n",
    "            'imputers': [de.DateFeatureExtractor(dtype='category')],\n",
    "            'encoders': [\n",
    "                # ne.TargetEncoder(target_type='continuous'),\n",
    "                ne.MultiTargetEncoder(drop_invariant=True, return_df=True),\n",
    "\n",
    "\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92d17a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_config = {'test_size': 0.2, 'val_size': 0.2, 'shuffle': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2f1155",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config={\"optimization\": \"grid\", \"grid_params\": grid_params, \"fit_params\": fit_params}\n",
    "encoding_pipeline = create_encoding_pipeline(encoders_dict=encoders_dict)\n",
    "dataset_config={'from_date': '15-01-2019', 'to_date': '30-12-2023', 'shift':[1, 2, 3, 4, 5, 6, 7], 'rolling_window':[7, 14], 'freq':'1D', 'split_config': split_config, 'encoding_pipeline': encoding_pipeline}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07d097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ars_experiment.run(dataset_config=dataset_config, model_config=model_config, find_best_features=True)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
