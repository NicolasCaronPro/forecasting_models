{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95cac579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(\n",
    "    os.path.join(os.path.dirname('__file__'), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51834613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3e194c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.encoding.encoders import *\n",
    "from src.encoding.tools import create_encoding_pipeline\n",
    "from src.models.sklearn_models import save_object, Model\n",
    "from src.models.sklearn_models_config import get_model\n",
    "from src.datasets.base_tabular_dataset import BaseTabularDataset\n",
    "from src.experiments.base_experiment import BaseExperiment\n",
    "import src.features as ft\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9706ae",
   "metadata": {},
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "992a7f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.basicConfig(level=logging.INFO, encoding=\"utf-8\",\n",
    "                    format=\"%(asctime)s: %(levelname)s: %(message)s\",\n",
    "                    datefmt='%Y/%m/%d %H:%M:%S',\n",
    "                    handlers=[logging.StreamHandler()])\n",
    "root_dir = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..'))\n",
    "config = ft.Config({'max_nan': 15, \"departement\": \"21\", \"root_dir\": root_dir, \"start\": '01-01-2019',\n",
    "                    \"stop\": '31-12-2023', \"logger\": logger, \"step_unit\": 'days', \"step_value\": 1,\n",
    "                    \"shift\": 0, \"rolling_window\": 0, \"etablissement\": \"CHU Dijon\", 'region':'BOURGOGNE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a21bd581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/13 18:15:03: INFO: Initialisation de la classe HopitalFeatures\n",
      "2024/09/13 18:15:03: INFO: Initialisation de la classe FireFightersFeatures\n"
     ]
    }
   ],
   "source": [
    "ars_features_class = [ft.AirQualityFeatures, ft.HopitalFeatures(config=config, include_emmergency_arrivals=True, include_nb_hospit=True), ft.EpidemiologicalFeatures, ft.FireFightersFeatures(config=config, include_calls=False),\n",
    "                      ft.GoogleTrendFeatures, ft.MeteorologicalFeatures, ft.SociologicalFeatures,\n",
    "                      ft.SportsCompetitionFeatures, ft.TrafficFeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c2f2b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/13 18:15:03: INFO: Initialisation de la classe BaseTabularDataset_Total_CHU Dijon\n",
      "2024/09/13 18:15:03: INFO: Initialisation de la classe AirQualityFeatures\n",
      "2024/09/13 18:15:03: INFO: Initialisation de la classe EpidemiologicalFeatures\n",
      "2024/09/13 18:15:03: INFO: Initialisation de la classe GoogleTrendFeatures\n",
      "2024/09/13 18:15:03: INFO: Initialisation de la classe MeteorologicalFeatures\n",
      "2024/09/13 18:15:03: INFO: Initialisation de la classe SociologicalFeatures\n",
      "2024/09/13 18:15:03: INFO: Initialisation de la classe SportsCompetitionFeatures\n",
      "2024/09/13 18:15:03: INFO: Initialisation de la classe TrafficFeatures\n",
      "2024/09/13 18:15:03: INFO: Fetching data for BaseTabularDataset_Total_CHU Dijon...\n",
      "2024/09/13 18:15:03: INFO: Fetching data from AirQualityFeatures({'max_nan': 15, 'departement': '21', 'root_dir': '/home/maxime/Documents/WORKSPACES/forecasting_models', 'start': '01-01-2019', 'stop': '31-12-2023', 'logger': <RootLogger root (INFO)>, 'step_unit': 'days', 'step_value': 1, 'shift': 0, 'rolling_window': 0, 'etablissement': 'CHU Dijon', 'region': 'BOURGOGNE'})\n",
      "2024/09/13 18:15:03: INFO: Fetching data for AirQualityFeatures...\n",
      "2024/09/13 18:15:03: INFO: On regarde la qualité de l'air\n",
      "2024/09/13 18:15:03: INFO: On s'intéresse aux codes : FR26005, FR26010, FR26014, FR26094\n",
      "2024/09/13 18:15:03: INFO: On relit le dataframe d'archive de l'air\n",
      "2024/09/13 18:15:03: INFO: Fin de la gestion de la qualité de l'air en 0.01 s.\n",
      "2024/09/13 18:15:03: INFO: Saving data for AirQualityFeatures...\n",
      "2024/09/13 18:15:03: INFO: Fetching data from HopitalFeatures({'max_nan': 15, 'departement': '21', 'root_dir': '/home/maxime/Documents/WORKSPACES/forecasting_models', 'start': '01-01-2019', 'stop': '31-12-2023', 'logger': <RootLogger root (INFO)>, 'step_unit': 'days', 'step_value': 1, 'shift': 0, 'rolling_window': 0, 'etablissement': 'CHU Dijon', 'region': 'BOURGOGNE'})\n",
      "2024/09/13 18:15:03: INFO: Fetching data for HopitalFeatures...\n",
      "2024/09/13 18:15:03: INFO: Intégration de la target\n",
      "2024/09/13 18:15:03: INFO:   - Chargement des données de CHU Dijon depuis le fichier Excel\n",
      "2024/09/13 18:15:03: INFO: Intégration du déménagement de l'HNFC\n",
      "2024/09/13 18:15:03: INFO: Saving data for HopitalFeatures...\n",
      "2024/09/13 18:15:03: INFO: Fetching data from EpidemiologicalFeatures({'max_nan': 15, 'departement': '21', 'root_dir': '/home/maxime/Documents/WORKSPACES/forecasting_models', 'start': '01-01-2019', 'stop': '31-12-2023', 'logger': <RootLogger root (INFO)>, 'step_unit': 'days', 'step_value': 1, 'shift': 0, 'rolling_window': 0, 'etablissement': 'CHU Dijon', 'region': 'BOURGOGNE'})\n",
      "2024/09/13 18:15:03: INFO: Fetching data for EpidemiologicalFeatures...\n",
      "2024/09/13 18:15:03: INFO: On s'occupe de l'incidence des maladies d'après Sentinelles\n",
      "2024/09/13 18:15:03: INFO:   - on regarde l'incidence de grippe pour la région BOURGOGNE\n",
      "2024/09/13 18:15:03: INFO: Chargement du modèle de prédiction pour grippe\n",
      "2024/09/13 18:15:04: INFO: Modèle grippe chargé\n",
      "2024/09/13 18:15:04: INFO:     Pour la dernière date connue ('02/09/2024', semaine 202436), l'incidence était de 757\n",
      "2024/09/13 18:15:04: INFO:     La première date connue était '29/10/1984', semaine 198444\n",
      "2024/09/13 18:15:04: INFO:   - on regarde l'incidence de diarrhee pour la région BOURGOGNE\n",
      "2024/09/13 18:15:04: INFO: Chargement du modèle de prédiction pour diarrhee\n",
      "2024/09/13 18:15:05: INFO: Modèle diarrhee chargé\n",
      "2024/09/13 18:15:05: INFO:     Pour la dernière date connue ('02/09/2024', semaine 202436), l'incidence était de 822\n",
      "2024/09/13 18:15:05: INFO:     La première date connue était '03/12/1990', semaine 199049\n",
      "2024/09/13 18:15:05: INFO:   - on regarde l'incidence de varicelle pour la région BOURGOGNE\n",
      "2024/09/13 18:15:05: INFO: Chargement du modèle de prédiction pour varicelle\n",
      "2024/09/13 18:15:06: INFO: Modèle varicelle chargé\n",
      "2024/09/13 18:15:06: INFO:     Pour la dernière date connue ('02/09/2024', semaine 202436), l'incidence était de 214\n",
      "2024/09/13 18:15:06: INFO:     La première date connue était '03/12/1990', semaine 199049\n",
      "2024/09/13 18:15:06: INFO:   - on regarde l'incidence de ira pour la région BOURGOGNE\n",
      "2024/09/13 18:15:06: INFO: Chargement du modèle de prédiction pour ira\n",
      "2024/09/13 18:15:06: INFO: Modèle ira chargé\n",
      "2024/09/13 18:15:06: INFO:     Pour la dernière date connue ('02/09/2024', semaine 202436), l'incidence était de 1573\n",
      "2024/09/13 18:15:06: INFO:     La première date connue était '23/03/2020', semaine 202012\n",
      "2024/09/13 18:15:06: INFO:     Cette première date étant postérieure, à notre historique (commençant le '01/01/2019'), on complète les incidences par des 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 202012 ('16/03/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 202011 ('09/03/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 202010 ('02/03/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 202009 ('24/02/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 202008 ('17/02/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 202007 ('10/02/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 202006 ('03/02/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 202005 ('27/01/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 202004 ('20/01/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 202003 ('13/01/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 202002 ('06/01/2020') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 202001 ('30/12/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201952 ('23/12/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201951 ('16/12/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201950 ('09/12/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201949 ('02/12/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201948 ('25/11/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201947 ('18/11/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201946 ('11/11/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201945 ('04/11/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201944 ('28/10/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201943 ('21/10/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201942 ('14/10/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201941 ('07/10/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201940 ('30/09/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201939 ('23/09/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201938 ('16/09/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201937 ('09/09/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201936 ('02/09/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201935 ('26/08/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201934 ('19/08/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201933 ('12/08/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201932 ('05/08/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201931 ('29/07/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201930 ('22/07/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201929 ('15/07/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201928 ('08/07/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201927 ('01/07/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201926 ('24/06/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201925 ('17/06/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201924 ('10/06/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201923 ('03/06/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201922 ('27/05/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201921 ('20/05/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201920 ('13/05/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201919 ('06/05/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201918 ('29/04/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201917 ('22/04/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201916 ('15/04/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201915 ('08/04/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201914 ('01/04/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201913 ('25/03/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201912 ('18/03/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201911 ('11/03/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201910 ('04/03/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201909 ('25/02/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201908 ('18/02/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201907 ('11/02/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201906 ('04/02/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201905 ('28/01/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201904 ('21/01/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201903 ('14/01/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201902 ('07/01/2019') par 0\n",
      "2024/09/13 18:15:06: INFO:     On complète la semaine 201901 ('31/12/2018') par 0\n",
      "2024/09/13 18:15:06: INFO: Données sentinelles intégralement récupérées\n",
      "2024/09/13 18:15:07: INFO: Saving data for EpidemiologicalFeatures...\n",
      "2024/09/13 18:15:07: INFO: Fetching data from FireFightersFeatures({'max_nan': 15, 'departement': '21', 'root_dir': '/home/maxime/Documents/WORKSPACES/forecasting_models', 'start': '01-01-2019', 'stop': '31-12-2023', 'logger': <RootLogger root (INFO)>, 'step_unit': 'days', 'step_value': 1, 'shift': 0, 'rolling_window': 0, 'etablissement': 'CHU Dijon', 'region': 'BOURGOGNE'})\n",
      "2024/09/13 18:15:07: INFO: Fetching data for FireFightersFeatures...\n",
      "2024/09/13 18:15:07: INFO: Saving data for FireFightersFeatures...\n",
      "2024/09/13 18:15:07: INFO: Fetching data from GoogleTrendFeatures({'max_nan': 15, 'departement': '21', 'root_dir': '/home/maxime/Documents/WORKSPACES/forecasting_models', 'start': '01-01-2019', 'stop': '31-12-2023', 'logger': <RootLogger root (INFO)>, 'step_unit': 'days', 'step_value': 1, 'shift': 0, 'rolling_window': 0, 'etablissement': 'CHU Dijon', 'region': 'BOURGOGNE'})\n",
      "2024/09/13 18:15:07: INFO: Fetching data for GoogleTrendFeatures...\n",
      "2024/09/13 18:15:07: INFO: On récupère les données de Google Trends\n",
      "2024/09/13 18:15:07: INFO: On charge les données de Google Trends depuis le fichier\n",
      "2024/09/13 18:15:07: INFO: Données de Google Trends intégrées\n",
      "2024/09/13 18:15:07: INFO: Saving data for GoogleTrendFeatures...\n",
      "2024/09/13 18:15:07: INFO: Fetching data from MeteorologicalFeatures({'max_nan': 15, 'departement': '21', 'root_dir': '/home/maxime/Documents/WORKSPACES/forecasting_models', 'start': '01-01-2019', 'stop': '31-12-2023', 'logger': <RootLogger root (INFO)>, 'step_unit': 'days', 'step_value': 1, 'shift': 0, 'rolling_window': 0, 'etablissement': 'CHU Dijon', 'region': 'BOURGOGNE'})\n",
      "2024/09/13 18:15:07: INFO: Fetching data for MeteorologicalFeatures...\n",
      "2024/09/13 18:15:07: INFO: On récupère les archives Meteostat\n",
      "FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "2024/09/13 18:15:07: INFO: Saving data for MeteorologicalFeatures...\n",
      "2024/09/13 18:15:07: INFO: Fetching data from SociologicalFeatures({'max_nan': 15, 'departement': '21', 'root_dir': '/home/maxime/Documents/WORKSPACES/forecasting_models', 'start': '01-01-2019', 'stop': '31-12-2023', 'logger': <RootLogger root (INFO)>, 'step_unit': 'days', 'step_value': 1, 'shift': 0, 'rolling_window': 0, 'etablissement': 'CHU Dijon', 'region': 'BOURGOGNE'})\n",
      "2024/09/13 18:15:07: INFO: Fetching data for SociologicalFeatures...\n",
      "2024/09/13 18:15:07: INFO: On s'occupe des variables de vacances\n",
      "2024/09/13 18:15:07: INFO: On récupère la liste des jours fériés\n",
      "2024/09/13 18:15:07: INFO: On l'intègre au dataframe\n",
      "2024/09/13 18:15:07: INFO: On s'occupe des vacances en tant que tel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dijon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/13 18:15:07: INFO: Variables de vacances intégrées\n",
      "2024/09/13 18:15:07: INFO: On s'occupe des variables de confinement\n",
      "2024/09/13 18:15:07: INFO: Variables de confinement intégrées\n",
      "2024/09/13 18:15:07: INFO: On s'occupe des variables de Ramadan\n",
      "2024/09/13 18:15:07: INFO: Saving data for SociologicalFeatures...\n",
      "2024/09/13 18:15:07: INFO: Fetching data from SportsCompetitionFeatures({'max_nan': 15, 'departement': '21', 'root_dir': '/home/maxime/Documents/WORKSPACES/forecasting_models', 'start': '01-01-2019', 'stop': '31-12-2023', 'logger': <RootLogger root (INFO)>, 'step_unit': 'days', 'step_value': 1, 'shift': 0, 'rolling_window': 0, 'etablissement': 'CHU Dijon', 'region': 'BOURGOGNE'})\n",
      "2024/09/13 18:15:07: INFO: Fetching data for SportsCompetitionFeatures...\n",
      "2024/09/13 18:15:07: INFO: Intégration des données de football\n",
      "2024/09/13 18:15:07: INFO: Données de football intégrées\n",
      "2024/09/13 18:15:07: INFO: Saving data for SportsCompetitionFeatures...\n",
      "2024/09/13 18:15:07: INFO: Fetching data from TrafficFeatures({'max_nan': 15, 'departement': '21', 'root_dir': '/home/maxime/Documents/WORKSPACES/forecasting_models', 'start': '01-01-2019', 'stop': '31-12-2023', 'logger': <RootLogger root (INFO)>, 'step_unit': 'days', 'step_value': 1, 'shift': 0, 'rolling_window': 0, 'etablissement': 'CHU Dijon', 'region': 'BOURGOGNE'})\n",
      "2024/09/13 18:15:07: INFO: Fetching data for TrafficFeatures...\n",
      "2024/09/13 18:15:07: INFO: Intégration des données de trafic\n",
      "FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "2024/09/13 18:15:08: INFO: Saving data for TrafficFeatures...\n",
      "2024/09/13 18:15:08: INFO: Saving data for BaseTabularDataset_Total_CHU Dijon...\n"
     ]
    }
   ],
   "source": [
    "arsTabularDataset = BaseTabularDataset(target_colomns=['Total_CHU Dijon'],  # ,  'nb_vers_hospit'\n",
    "                                       config=config, features_class=ars_features_class)\n",
    "arsTabularDataset.fetch_data(save=True) # Fetch data from the features, do this only once, if you need smaller datasets, use the get_dataset method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbf79c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'early_stopping_rounds': 10,\n",
    "    # 'eval_set': [(arsTabularDataset.enc_X_val, arsTabularDataset.y_val)], # TODO: to be set in the experiment's run method\n",
    "    'verbosity': 0,\n",
    "    'n_estimators': 10000,\n",
    "    'learning_rate': 0.1,\n",
    "    'min_child_weight': 5,\n",
    "    # 'multi_strategy': 'one_output_per_tree',\n",
    "    # 'multi_strategy': 'multi_output_tree' \n",
    "}\n",
    "model = get_model(model_type='xgboost', name='XGBRegressor', device='cuda', task_type='regression', test_metrics='rmse', with_metric='w_rmse', params=model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25abf121",
   "metadata": {},
   "outputs": [],
   "source": [
    "ars_experiment = BaseExperiment(dataset=arsTabularDataset, model=model, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98c2c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    'max_depth': [3, 5, 7, 9, 11],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddc6873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {\n",
    "    'verbose': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c4f4ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders_dict = {\n",
    "    'number': {\n",
    "        'as_number': {\n",
    "            'imputers': [imputers.SimpleImputer(strategy='mean')],\n",
    "            'encoders': [\n",
    "                ne.StandardScaler(),\n",
    "\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    'category': {\n",
    "        'as_category': {\n",
    "            'imputers': [imputers.SimpleImputer(strategy='most_frequent')],\n",
    "            'encoders': [\n",
    "                # ne.TargetEncoder(target_type='continuous-multioutput'),\n",
    "                # ne.TargetEncoder(target_type='continuous'),\n",
    "                ne.MultiTargetEncoder(drop_invariant=True, return_df=True),\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    'datetime': {\n",
    "        'as_number': {\n",
    "            'imputers': [de.DateFeatureExtractor()],\n",
    "            'encoders': [\n",
    "                ne.CyclicalFeatures(drop_original=True)\n",
    "            ]\n",
    "        },\n",
    "        'as_category': {\n",
    "            'imputers': [de.DateFeatureExtractor(dtype='category')],\n",
    "            'encoders': [\n",
    "                # ne.TargetEncoder(target_type='continuous'),\n",
    "                ne.MultiTargetEncoder(drop_invariant=True, return_df=True),\n",
    "\n",
    "\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1565c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tes = ne.MultiTargetEncoder(drop_invariant=True, return_df=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b76c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tes.set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c31ece50",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_config = {'test_size': 0.2, 'val_size': 0.2, 'shuffle': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae2016f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating encoding pipeline\n"
     ]
    }
   ],
   "source": [
    "dataset_config={'from_date': '01-01-2019', 'to_date': '31-12-2023', 'shift':7, 'rolling_window':[7, 14], 'freq':'1YE', 'split_config': split_config}\n",
    "model_config={\"optimization\": \"grid\", \"grid_params\": grid_params, \"fit_params\": fit_params}\n",
    "encoding_pipeline = create_encoding_pipeline(encoders_dict=encoders_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ea821d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/13 18:15:08 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "2024/09/13 18:15:08: INFO: Running the experiment...\n",
      "2024/09/13 18:15:08: INFO: Augmentation des features...\n",
      "2024/09/13 18:15:08: INFO: Aggregating data by data type...\n",
      "2024/09/13 18:15:34 INFO mlflow.tracking._tracking_service.client: 🏃 View run run_29 at: http://127.0.0.1:8080/#/experiments/397958626087620787/runs/652073be21ed46a894d0a7a5d78056f3.\n",
      "2024/09/13 18:15:34 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:8080/#/experiments/397958626087620787.\n",
      "2024/09/13 18:15:34 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FeatureUnion]  (step 1 of 4) Processing columntransformer-1, total=   0.1s\n",
      "[FeatureUnion]  (step 2 of 4) Processing columntransformer-2, total=   0.0s\n",
      "[FeatureUnion]  (step 3 of 4) Processing columntransformer-3, total=   0.0s\n",
      "[FeatureUnion]  (step 4 of 4) Processing columntransformer-4, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/13 18:15:34 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "dataset = ars_experiment.run(dataset_config=dataset_config, model_config=model_config, encoding_pipeline=encoding_pipeline, find_best_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ddce312",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ars_experiment.dataset\n",
    "data = dataset.data\n",
    "enc_data = dataset.enc_data\n",
    "train_set = dataset.train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "322a6415",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dataset.X_train\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "438e738c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/13 18:16:30: INFO: Aggregating data by data type...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1YE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_subplots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/forecasting_models/src/features/base_features.py:649\u001b[0m, in \u001b[0;36mBaseFeature.plot\u001b[0;34m(self, from_date, to_date, features_names, freq, max_subplots, data)\u001b[0m\n\u001b[1;32m    646\u001b[0m num_figures \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mceil(num_vars \u001b[38;5;241m/\u001b[39m max_subplots)\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (freq \u001b[38;5;241m!=\u001b[39m pd\u001b[38;5;241m.\u001b[39minfer_freq(data\u001b[38;5;241m.\u001b[39mindex)) \u001b[38;5;129;01mand\u001b[39;00m (freq \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (freq \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m pd\u001b[38;5;241m.\u001b[39minfer_freq(data\u001b[38;5;241m.\u001b[39mindex)) \u001b[38;5;129;01mand\u001b[39;00m (freq \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m pd\u001b[38;5;241m.\u001b[39minfer_freq(data\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (freq \u001b[38;5;241m!=\u001b[39m pd\u001b[38;5;241m.\u001b[39minfer_freq(data\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 649\u001b[0m     agg_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate_data_by_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43magg_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnumber\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mrelative_frequency\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    651\u001b[0m     agg_data \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/forecasting_models/src/features/base_features.py:462\u001b[0m, in \u001b[0;36mBaseFeature.aggregate_data_by_dtype\u001b[0;34m(self, agg_dict, data, freq, flatten)\u001b[0m\n\u001b[1;32m    459\u001b[0m grouped_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby(grouper)\n\u001b[1;32m    461\u001b[0m \u001b[38;5;66;03m# Appliquer les agrégations\u001b[39;00m\n\u001b[0;32m--> 462\u001b[0m aggregated_df \u001b[38;5;241m=\u001b[39m \u001b[43mgrouped_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapply_aggregations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(aggregated_df, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m    466\u001b[0m     aggregated_df \u001b[38;5;241m=\u001b[39m aggregated_df\u001b[38;5;241m.\u001b[39mto_frame()\u001b[38;5;241m.\u001b[39munstack(level\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m.\u001b[39mdroplevel(\u001b[38;5;241m0\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1824\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, include_groups, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1822\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1823\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1824\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1825\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1826\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, Series)\n\u001b[1;32m   1827\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1828\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1829\u001b[0m         ):\n\u001b[1;32m   1830\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1831\u001b[0m                 message\u001b[38;5;241m=\u001b[39m_apply_groupings_depr\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1832\u001b[0m                     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1835\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1836\u001b[0m             )\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1885\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m   1852\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1857\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1883\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1885\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_groupwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1886\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1887\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/groupby/ops.py:919\u001b[0m, in \u001b[0;36mBaseGrouper.apply_groupwise\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    918\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 919\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    921\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/forecasting_models/src/features/base_features.py:455\u001b[0m, in \u001b[0;36mBaseFeature.aggregate_data_by_dtype.<locals>.apply_aggregations\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, funcs \u001b[38;5;129;01min\u001b[39;00m column_agg_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;66;03m# print(group[col])\u001b[39;00m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# self.logger.info(f\"Aggregating column {col}...\")\u001b[39;00m\n\u001b[1;32m    453\u001b[0m     aggregated[col] \u001b[38;5;241m=\u001b[39m unified_apply_func(group[col], funcs)\n\u001b[0;32m--> 455\u001b[0m     concat \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43maggregated\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concat\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/reshape/concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/reshape/concat.py:644\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m     new_index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(res))\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     new_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    646\u001b[0m mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(sample\u001b[38;5;241m.\u001b[39m_mgr)\u001b[38;5;241m.\u001b[39mfrom_array(res, index\u001b[38;5;241m=\u001b[39mnew_index)\n\u001b[1;32m    648\u001b[0m result \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(mgr, axes\u001b[38;5;241m=\u001b[39mmgr\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/reshape/concat.py:702\u001b[0m, in \u001b[0;36m_Concatenator.new_axes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_axes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Index]:\n\u001b[1;32m    701\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_result_dim()\n\u001b[0;32m--> 702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concat_axis \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_comb_axis(i)\n\u001b[1;32m    704\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndim)\n\u001b[1;32m    705\u001b[0m     ]\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/reshape/concat.py:703\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_axes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Index]:\n\u001b[1;32m    701\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_result_dim()\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 703\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concat_axis\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_comb_axis(i)\n\u001b[1;32m    704\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndim)\n\u001b[1;32m    705\u001b[0m     ]\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/reshape/concat.py:762\u001b[0m, in \u001b[0;36m_Concatenator._get_concat_axis\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m     concat_axis \u001b[38;5;241m=\u001b[39m _concat_indexes(indexes)\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 762\u001b[0m     concat_axis \u001b[38;5;241m=\u001b[39m \u001b[43m_make_concat_multiindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindexes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_check_integrity(concat_axis)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concat_axis\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/reshape/concat.py:807\u001b[0m, in \u001b[0;36m_make_concat_multiindex\u001b[0;34m(indexes, keys, levels, names)\u001b[0m\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m level\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[1;32m    805\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLevel values not unique: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mall_indexes_same\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexes\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(level\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;28;01mfor\u001b[39;00m level \u001b[38;5;129;01min\u001b[39;00m levels):\n\u001b[1;32m    808\u001b[0m     codes_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;66;03m# things are potentially different sizes, so compute the exact codes\u001b[39;00m\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;66;03m# for each level and pass those to MultiIndex.from_arrays\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/indexes/api.py:383\u001b[0m, in \u001b[0;36mall_indexes_same\u001b[0;34m(indexes)\u001b[0m\n\u001b[1;32m    381\u001b[0m itr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(indexes)\n\u001b[1;32m    382\u001b[0m first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(itr)\n\u001b[0;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfirst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/indexes/api.py:383\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    381\u001b[0m itr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(indexes)\n\u001b[1;32m    382\u001b[0m first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(itr)\n\u001b[0;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43mfirst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m itr)\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:5649\u001b[0m, in \u001b[0;36mIndex.equals\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   5645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype):\n\u001b[1;32m   5646\u001b[0m     \u001b[38;5;66;03m# All EA-backed Index subclasses override equals\u001b[39;00m\n\u001b[1;32m   5647\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m other\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 5649\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_equivalent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/dtypes/missing.py:531\u001b[0m, in \u001b[0;36marray_equivalent\u001b[0;34m(left, right, strict_nan, dtype_equal)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;66;03m# Slow path when we allow comparing different dtypes.\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;66;03m# Object arrays can contain None, NaN and NaT.\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;66;03m# string dtypes must be come to this path for NumPy 1.7.1 compat\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOSU\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m right\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOSU\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;66;03m# Note: `in \"OSU\"` is non-trivially faster than `in [\"O\", \"S\", \"U\"]`\u001b[39;00m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;66;03m#  or `in (\"O\", \"S\", \"U\")`\u001b[39;00m\n\u001b[0;32m--> 531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_equivalent_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# NaNs can occur in float and complex arrays.\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/WORKSPACES/ARS_Project/.venv/lib/python3.10/site-packages/pandas/core/dtypes/missing.py:576\u001b[0m, in \u001b[0;36m_array_equivalent_object\u001b[0;34m(left, right, strict_nan)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 576\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_equivalent_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39marray_equivalent_object(left[\u001b[38;5;241m~\u001b[39mmask], right[\u001b[38;5;241m~\u001b[39mmask]):\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset.plot(freq='1YE', max_subplots=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc238c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f9e045d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/13 18:15:34: INFO: Augmentation des features...\n",
      "2024/09/13 18:15:35: INFO: Aggregating data by data type...\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.get_dataset(**dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c282f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_data = dataset.enc_data\n",
    "enc_data"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
