{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import datetime as dt\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import pathlib\n",
    "\n",
    "# nom_logs = os.path.basename(\"presentation\")\n",
    "# if os.path.isfile(f'{dir_logs}/{nom_logs}.log'):\n",
    "#     shutil.move(f'{dir_logs}/{nom_logs}.log', f'{dir_logs}/{nom_logs}_old.log')\n",
    "\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "logFormatter = logging.Formatter(\"%(asctime)s [%(levelname)-5.5s]  %(message)s\")\n",
    "\n",
    "# # Handler pour écrire les logs dans un fichier\n",
    "# fileHandler = logging.FileHandler(f\"{dir_logs}/{nom_logs}.log\")\n",
    "# fileHandler.setFormatter(logFormatter)\n",
    "# logger.addHandler(fileHandler)\n",
    "\n",
    "# Handler pour afficher les logs dans le terminal\n",
    "streamHandler = logging.StreamHandler(stream=sys.stdout)\n",
    "streamHandler.setFormatter(logFormatter)\n",
    "logger.addHandler(streamHandler)\n",
    "\n",
    "\n",
    "# logger.info(f\"Répertoire racine du projet : {p}\")\n",
    "# logger.info(f\"Répertoire des logs : {dir_logs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-28 11:07:04,738 [INFO ]  On s'intéresse aux matchs de foot\n",
      "2024-05-28 11:07:04,739 [INFO ]    - On considère que l'impact d'un match est de 5h\n"
     ]
    }
   ],
   "source": [
    "##################################################################################################\n",
    "#               Match de foot\n",
    "##################################################################################################\n",
    "\n",
    "\n",
    "START = dt.datetime.strptime(\"2018-01-01\", \"%Y-%m-%d\")\n",
    "STOP_DATA = dt.datetime.strptime(\"2023-12-31\", \"%Y-%m-%d\")\n",
    "# END = dt.datetime.strptime(\"2021-08-31\", \"%Y-%m-%d\")\n",
    "logger.info(\"On s'intéresse aux matchs de foot\")\n",
    "duree = 5\n",
    "logger.info(f\"  - On considère que l'impact d'un match est de {duree}h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.ligue2.fr/clubs/Calendar?id=dijon-fco\n",
    "# https://www.ligue2.fr/clubs/Calendar?id=fc-sochaux-montbeliard\n",
    "def getDateAutherClubs(club, lg, lastDateYear):\n",
    "    cptSaison = 0\n",
    "    dateDispo = []\n",
    "    saisons = []\n",
    "    urlvr = \"https://www.ligue\" + lg + \".fr/clubs/Calendar?id=\" + club\n",
    "    try:\n",
    "        r = requests.get(urlvr)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        each_div = soup.findAll('div', {'class': 'CustomSelect-season'})[2:]\n",
    "        for div in each_div:\n",
    "            for el in div.findAll('li', {'class': 'CustomSelect-seasonItem'}):\n",
    "                if cptSaison < 4:\n",
    "                    cptSaison += 1\n",
    "                    continue\n",
    "\n",
    "                if lastDateYear == '':\n",
    "                    saisons.append(el.findAll('a')[0]['href'])\n",
    "                else:\n",
    "                    if (int(lastDateYear) <= int(el.findAll('a')[0].text.split('/')[0])\n",
    "                            or int(lastDateYear) <= int(el.findAll('a')[0].text.split('/')[1])):\n",
    "                        saisons.append(el.findAll('a')[0]['href'])\n",
    "    except:\n",
    "        logger.warning(\"Problème avec la Ligue\")\n",
    "        # with open(dir_logs / 'probleme_de_connexion.csv', 'a') as f:\n",
    "        #     f.write(f'{dt.datetime.now()},Foot2\\n')\n",
    "    for saison in saisons:\n",
    "        try:\n",
    "            r = requests.get(saison)\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            each_div = soup.findAll('div', {'class': 'CalendarClub-dateTime'})\n",
    "            for cal in each_div:\n",
    "                var = ''\n",
    "                for temps in cal.findAll('span'):\n",
    "                    var += temps.text.strip() + ' '\n",
    "                if 'Reporté' in var or '--:--' in var:\n",
    "                    continue\n",
    "                dateDispo.append(dt.datetime.strptime(var.strip(), '%d/%m/%Y %Hh%M').strftime('%d/%m/%Y 00:00:00'))\n",
    "        except:\n",
    "            logger.warning(\"Problème de récupération des saisons de foot\")\n",
    "            # with open(dir_logs / 'probleme_de_connexion.csv', 'a') as f:\n",
    "            #     f.write(f'{dt.datetime.now()},Foot3\\n')\n",
    "    return dateDispo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadArchiveFoot(numcomp, competitionName):\n",
    "    dateDispo = []\n",
    "    tabTotal = []\n",
    "    now = dt.datetime.now()\n",
    "    now = now.strftime('%Y-%m-%d 00:00:00')\n",
    "    comps = ['france/ligue-1/', 'europe/ligue-des-champions/']\n",
    "    urlvr = \"https://www.footendirect.com/football/\" + comps[numcomp]\n",
    "    r = requests.get(urlvr)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    res = soup.findAll('ul', {'class': 'dropdown-select'})\n",
    "    date = START - dt.timedelta(days=1) #dt.datetime(2014, 12, 31, 23, 0, 0)\n",
    "    if len(res) > 0:\n",
    "        each_ul = res[0]\n",
    "        saisons = []\n",
    "        phases = [11, 24]\n",
    "        if numcomp == 1:\n",
    "            phases = [1, 2, 9]\n",
    "        elif numcomp == 2:\n",
    "            phases = [2, 9]\n",
    "        for each_a in each_ul.findAll('a'):\n",
    "            if each_a.text == '2013/2014' or each_a.text == '2014':\n",
    "                break\n",
    "            else:\n",
    "                saisons.append(each_a['href'])\n",
    "        for elt in reversed(saisons):\n",
    "            urlvr = \"https://www.footendirect.com\" + elt\n",
    "            r = requests.get(urlvr)\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            res = soup.findAll('ul', {'class': 'dropdown-select'})\n",
    "            if len(res) >= 2:\n",
    "                for ph in phases:\n",
    "                    urlvr = \"https://www.footendirect.com\" + elt + \"&competitionStageType1Id=\" + str(\n",
    "                        ph) + \"&competitionRoundId=2\"\n",
    "                    r = requests.get(urlvr)\n",
    "                    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "                    res1 = soup.findAll('table', {'class': 'table-condensed'})\n",
    "                    if len(res1) > 0:\n",
    "                        each_table = res1[0]\n",
    "                        for tr in each_table.findAll('tr', attrs={'data-date': True}):\n",
    "                            dateDispo.append(\n",
    "                                dt.datetime.strptime(tr['data-date'], '%Y-%m-%d %H:%M').strftime('%d/%m/%Y 00:00:00'))\n",
    "            else:\n",
    "                logger.warning(\"Foot : Le retour de findall n'avait pas assez d'éléments\")\n",
    "            urlvr = \"https://www.footendirect.com\" + elt + \"&competitionRoundId=\" + \"&competitionStageType1Id=24\"\n",
    "            r = requests.get(urlvr)\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            res2 = soup.findAll('table', {'class': 'table-condensed'})\n",
    "            if len(res2) > 0:\n",
    "                each_table = res2[0]\n",
    "                for tr in each_table.findAll('tr', attrs={'data-date': True}):\n",
    "                    dateDispo.append(\n",
    "                        dt.datetime.strptime(tr['data-date'], '%Y-%m-%d %H:%M').strftime('%d/%m/%Y 00:00:00'))\n",
    "    # recherche des matchs des clubs dijon et montbeliard dans les deux ligues (1 et 2)\n",
    "    if numcomp == 0:\n",
    "        dtDijon = getDateAutherClubs('dijon-fco', '1', '') + getDateAutherClubs('dijon-fco', '2', '')\n",
    "        dtmontb = getDateAutherClubs('fc-sochaux-montbeliard', '1', '') + getDateAutherClubs('fc-sochaux-montbeliard',\n",
    "                                                                                             '2', '')\n",
    "        dtFinal = dtDijon + dtmontb\n",
    "        dtFinal = removeDuplicatedDate(dtFinal)\n",
    "        dateDispo = dateDispo + dtFinal\n",
    "    while now != date.strftime('%Y-%m-%d 00:00:00'):\n",
    "        tab = []\n",
    "        date += dt.timedelta(days=1)\n",
    "        dateVer = date.strftime('%Y-%m-%d')\n",
    "        tab.append(dateVer)\n",
    "        if dateVer in dateDispo:\n",
    "            tab.append('1')\n",
    "        else:\n",
    "            tab.append('0')\n",
    "        tabTotal.append(tab)\n",
    "    df = pd.DataFrame(tabTotal, columns=['date_entree', competitionName])\n",
    "    df.to_csv(dir_foot / (competitionName + \".csv\"), index=False, date_format='%Y-%m-%d')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateVariablesFoot(dataArchive, numcomp, competitionName):\n",
    "    \n",
    "    lastDate = dt.datetime.strptime(dataArchive.iloc[-1].date_entree, '%Y-%m-%d')\n",
    "\n",
    "    lastDateYear = lastDate.year\n",
    "    comps = ['france/ligue-1/', 'europe/ligue-des-champions/']\n",
    "    urlvr = \"https://www.footendirect.com/football/\" + comps[numcomp]\n",
    "    saisons = []\n",
    "    phases = [11, 24]\n",
    "    if numcomp == 1:\n",
    "        phases = [1, 2, 9]\n",
    "    elif numcomp == 2:\n",
    "        phases = [2, 9]\n",
    "    try:\n",
    "        r = requests.get(urlvr)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        each_ul = soup.findAll('ul', {'class': 'dropdown-select'})[0]\n",
    "        for each_a in each_ul.findAll('a'):\n",
    "            if ((numcomp != 2 and (int(lastDateYear) <= int(each_a.text.split('/')[0])\n",
    "                                    or int(lastDateYear) <= int(each_a.text.split('/')[1])))\n",
    "                    or (numcomp == 2 and int(lastDateYear) <= int(each_a.text))):\n",
    "                saisons.append(each_a['href'])\n",
    "    except:\n",
    "        logger.error(\"soup.findAll n'a pas d'éléments\")\n",
    "    dateDispo = []\n",
    "    date = dt.datetime(int(lastDateYear - 1), 12, 31, 0, 0, 0)\n",
    "    now = dt.datetime.now()\n",
    "    now = now.strftime('%Y-%m-%d 00:00:00')\n",
    "    tabTotal = []\n",
    "    for elt in reversed(saisons):\n",
    "        urlvr = \"https://www.footendirect.com\" + elt\n",
    "        try:\n",
    "            # r = requests.get(urlvr)\n",
    "            # soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            # each_ul = soup.findAll('ul', {'class': 'dropdown-select'})[1]\n",
    "            for ph in phases:\n",
    "                urlvr = \"https://www.footendirect.com\" + elt + \"&competitionStageType1Id=\" + str(\n",
    "                    ph) + \"&competitionRoundId=2\"\n",
    "                r = requests.get(urlvr)\n",
    "                soup = BeautifulSoup(r.text, 'html.parser')\n",
    "                res = soup.findAll('table', {'class': 'table-condensed'})\n",
    "                if len(res) > 0:\n",
    "                    each_table = res[0]\n",
    "                    for tr in each_table.findAll('tr', attrs={'data-date': True}):\n",
    "                        dateDispo.append(\n",
    "                            dt.datetime.strptime(tr['data-date'], '%Y-%m-%d %H:%M').strftime('%d/%m/%Y 00:00:00'))\n",
    "            urlvr = \"https://www.footendirect.com\" + elt + \"&competitionRoundId=\" + \"&competitionStageType1Id=24\"\n",
    "            r = requests.get(urlvr)\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            each_table = soup.findAll('table', {'class': 'table-condensed'})[0]\n",
    "            for tr in each_table.findAll('tr', attrs={'data-date': True}):\n",
    "                dateDispo.append(dt.datetime.strptime(tr['data-date'], '%Y-%m-%d %H:%M').strftime('%d/%m/%Y 00:00:00'))\n",
    "        except:\n",
    "            logging.error('Problème de téléchargement footendirect.com')\n",
    "            with open(dir_logs / 'probleme_de_connexion.csv', 'a') as f:\n",
    "                f.write(f'{dt.datetime.now()},Foot1\\n')\n",
    "    if False: #numcomp == 0:\n",
    "        dtDijon = getDateAutherClubs('dijon-fco', '1', lastDateYear) + getDateAutherClubs('dijon-fco', '2',\n",
    "                                                                                          lastDateYear)\n",
    "        dtmontb = getDateAutherClubs('fc-sochaux-montbeliard', '1', lastDateYear) + getDateAutherClubs(\n",
    "            'fc-sochaux-montbeliard', '2', lastDateYear)\n",
    "        dtFinal = dtDijon + dtmontb\n",
    "        dtFinal = removeDuplicatedDate(dtFinal)\n",
    "        dateDispo = dateDispo + dtFinal\n",
    "    print(now, date.strftime('%Y-%m-%d 00:00:00'))\n",
    "    while now != date.strftime('%Y-%m-%d 00:00:00'):\n",
    "        tab = []\n",
    "        date += dt.timedelta(days=1)\n",
    "        dateVer = date.strftime('%Y-%m-%d')\n",
    "        tab.append(dateVer)\n",
    "        if dateVer in dateDispo:\n",
    "            tab.append('1')\n",
    "        else:\n",
    "            tab.append('0')\n",
    "            tabTotal.append(tab)\n",
    "    df = pd.DataFrame(tabTotal, columns=['date_entree', competitionName])\n",
    "    print(competitionName)\n",
    "    datatFinal = pd.concat(\n",
    "        [dataArchive[:dataArchive[dataArchive[\"date_entree\"] == str(lastDateYear) + \"-01-01\"].index[0] + 1],\n",
    "         df[df[df[\"date_entree\"] == str(lastDateYear) + \"-01-01\"].index[0] + 1:]])\n",
    "    datatFinal.to_csv(dir_foot / (competitionName + \".csv\"), index=False)\n",
    "    return datatFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDuplicatedDate(dtfi):\n",
    "    unique_dates = []\n",
    "    for fi in dtfi:\n",
    "        if fi not in unique_dates:\n",
    "            unique_dates.append(fi)\n",
    "    return unique_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_foot = pathlib.Path(\"__file__\").resolve().parents[0]\n",
    "dico_foot = {\n",
    "    'LGF1': {'nom': 'Ligue 1',\n",
    "             'code': 0},\n",
    "    'CL': {'nom': 'Ligue des champions',\n",
    "           'code': 1}\n",
    "}\n",
    "\n",
    "df0 = None\n",
    "for foot in dico_foot:\n",
    "    file_name = dir_foot / f\"{foot}.csv\"\n",
    "    if not file_name.is_file():\n",
    "        logger.info(f\"  - on récupère l'archive de la {dico_foot[foot]['nom']}\")\n",
    "        downloadArchiveFoot(dico_foot[foot]['code'], foot)\n",
    "    logger.info(f\"  - On met à jour l'archive de la {dico_foot[foot]['nom']}\")\n",
    "    dataUpdateFoot = pd.read_csv(dir_foot / f\"{foot}.csv\", sep=',')\n",
    "    \n",
    "    df = updateVariablesFoot(dataUpdateFoot, dico_foot[foot]['code'], foot)\n",
    "    if df0 is None:\n",
    "        df0 = pd.DataFrame(index=df['date_entree'])\n",
    "    df.set_index(\"date_entree\", inplace=True)\n",
    "    for k in range(duree):\n",
    "        df[f\"{foot}-{k}\"] = df[foot].shift(k)\n",
    "    df = df.bfill()[[f\"{foot}-{k}\" for k in range(duree)]].astype(int)\n",
    "    df[f'match_{foot}'] = df[[f\"{foot}-{k}\" for k in range(duree)]].sum(axis=1)\n",
    "    df = df[f'match_{foot}']\n",
    "    df0 = pd.merge(df0, df, left_index=True, right_index=True)\n",
    "\n",
    "logger.info(f\"  - On crée les variables pour les jours à venir\")\n",
    "for col in df0.columns:\n",
    "    for k in range(2, 13, 2):\n",
    "        df0[f\"{col}-{k}\"] = df0[col].shift(-k)\n",
    "    df0 = df0.copy()\n",
    "    #for l in range(15):\n",
    "    #    df0[f'{col}-av_{l}'] = df0.ffill()[[f\"{col}-{k}\" for k in range(1, 13)]].shift(12 * l).sum(axis=1)\n",
    "\n",
    "#logger.info(f\"  - On enregistre le csv foot_all.csv\")\n",
    "#df0.to_csv(dir_foot / 'foot_all.csv')\n",
    "\n",
    "df0.reset_index(inplace=True)\n",
    "try:\n",
    "    df0['date_entree'] = pd.to_datetime(df0['date_entree'])\n",
    "except:\n",
    "    df0['date_entree'] = pd.to_datetime(df0['date_entree'], format=\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "df0 = df0.loc[df0['date_entree'] <= STOP_DATA]\n",
    "df0 = df0.loc[START <= df0['date_entree']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-28 11:36:20,490 [INFO ]    - On récupère les matchs du 20/08/2023\n",
      "2024-05-28 11:36:21,763 [INFO ]    - On récupère les matchs du 21/08/2023\n",
      "2024-05-28 11:36:23,613 [INFO ]    - On récupère les matchs du 22/08/2023\n",
      "2024-05-28 11:36:25,968 [INFO ]    - On récupère les matchs du 23/08/2023\n",
      "2024-05-28 11:36:27,699 [INFO ]    - On récupère les matchs du 24/08/2023\n",
      "2024-05-28 11:36:29,733 [INFO ]    - On récupère les matchs du 25/08/2023\n",
      "2024-05-28 11:36:32,113 [INFO ]    - On récupère les matchs du 26/08/2023\n",
      "2024-05-28 11:36:34,362 [INFO ]    - On récupère les matchs du 27/08/2023\n",
      "2024-05-28 11:36:36,502 [INFO ]    - On récupère les matchs du 28/08/2023\n",
      "2024-05-28 11:36:38,395 [INFO ]    - On récupère les matchs du 29/08/2023\n",
      "2024-05-28 11:36:40,436 [INFO ]    - On récupère les matchs du 30/08/2023\n",
      "2024-05-28 11:36:42,307 [INFO ]    - On récupère les matchs du 31/08/2023\n",
      "2024-05-28 11:36:44,279 [INFO ]    - On récupère les matchs du 01/09/2023\n",
      "2024-05-28 11:36:46,204 [INFO ]    - On récupère les matchs du 02/09/2023\n",
      "2024-05-28 11:36:48,112 [INFO ]    - On récupère les matchs du 03/09/2023\n",
      "2024-05-28 11:36:49,882 [INFO ]    - On récupère les matchs du 04/09/2023\n",
      "2024-05-28 11:36:51,736 [INFO ]    - On récupère les matchs du 05/09/2023\n",
      "2024-05-28 11:36:53,963 [INFO ]    - On récupère les matchs du 06/09/2023\n",
      "2024-05-28 11:36:56,247 [INFO ]    - On récupère les matchs du 07/09/2023\n",
      "2024-05-28 11:36:58,082 [INFO ]    - On récupère les matchs du 08/09/2023\n",
      "2024-05-28 11:37:00,374 [INFO ]    - On récupère les matchs du 09/09/2023\n",
      "2024-05-28 11:37:02,448 [INFO ]    - On récupère les matchs du 10/09/2023\n",
      "2024-05-28 11:37:05,629 [INFO ]    - On récupère les matchs du 11/09/2023\n",
      "2024-05-28 11:37:07,422 [INFO ]    - On récupère les matchs du 12/09/2023\n",
      "2024-05-28 11:37:09,438 [INFO ]    - On récupère les matchs du 13/09/2023\n",
      "2024-05-28 11:37:12,113 [INFO ]    - On récupère les matchs du 14/09/2023\n",
      "2024-05-28 11:37:15,984 [INFO ]    - On récupère les matchs du 15/09/2023\n",
      "2024-05-28 11:37:18,030 [INFO ]    - On récupère les matchs du 16/09/2023\n",
      "2024-05-28 11:37:19,922 [INFO ]    - On récupère les matchs du 17/09/2023\n",
      "2024-05-28 11:37:21,797 [INFO ]    - On récupère les matchs du 18/09/2023\n",
      "2024-05-28 11:37:24,601 [INFO ]    - On récupère les matchs du 19/09/2023\n",
      "2024-05-28 11:37:27,368 [INFO ]    - On récupère les matchs du 20/09/2023\n",
      "2024-05-28 11:37:29,566 [INFO ]    - On récupère les matchs du 21/09/2023\n",
      "2024-05-28 11:37:32,044 [INFO ]    - On récupère les matchs du 22/09/2023\n",
      "2024-05-28 11:37:34,287 [INFO ]    - On récupère les matchs du 23/09/2023\n",
      "2024-05-28 11:37:36,140 [INFO ]    - On récupère les matchs du 24/09/2023\n",
      "2024-05-28 11:37:38,355 [INFO ]    - On récupère les matchs du 25/09/2023\n",
      "2024-05-28 11:37:40,595 [INFO ]    - On récupère les matchs du 26/09/2023\n",
      "2024-05-28 11:37:42,847 [INFO ]    - On récupère les matchs du 27/09/2023\n",
      "2024-05-28 11:37:45,351 [INFO ]    - On récupère les matchs du 28/09/2023\n",
      "2024-05-28 11:37:47,369 [INFO ]    - On récupère les matchs du 29/09/2023\n",
      "2024-05-28 11:37:49,385 [INFO ]    - On récupère les matchs du 30/09/2023\n",
      "2024-05-28 11:37:51,971 [INFO ]    - On récupère les matchs du 01/10/2023\n",
      "2024-05-28 11:37:54,085 [INFO ]    - On récupère les matchs du 02/10/2023\n",
      "2024-05-28 11:37:56,810 [INFO ]    - On récupère les matchs du 03/10/2023\n",
      "2024-05-28 11:37:58,944 [INFO ]    - On récupère les matchs du 04/10/2023\n",
      "2024-05-28 11:38:00,836 [INFO ]    - On récupère les matchs du 05/10/2023\n",
      "2024-05-28 11:38:02,733 [INFO ]    - On récupère les matchs du 06/10/2023\n",
      "2024-05-28 11:38:05,471 [INFO ]    - On récupère les matchs du 07/10/2023\n",
      "2024-05-28 11:38:07,491 [INFO ]    - On récupère les matchs du 08/10/2023\n",
      "2024-05-28 11:38:09,525 [INFO ]    - On récupère les matchs du 09/10/2023\n",
      "2024-05-28 11:38:11,553 [INFO ]    - On récupère les matchs du 10/10/2023\n",
      "2024-05-28 11:38:13,314 [INFO ]    - On récupère les matchs du 11/10/2023\n",
      "2024-05-28 11:38:15,173 [INFO ]    - On récupère les matchs du 12/10/2023\n",
      "2024-05-28 11:38:17,613 [INFO ]    - On récupère les matchs du 13/10/2023\n",
      "2024-05-28 11:38:19,517 [INFO ]    - On récupère les matchs du 14/10/2023\n",
      "2024-05-28 11:38:21,811 [INFO ]    - On récupère les matchs du 15/10/2023\n",
      "2024-05-28 11:38:23,809 [INFO ]    - On récupère les matchs du 16/10/2023\n",
      "2024-05-28 11:38:25,701 [INFO ]    - On récupère les matchs du 17/10/2023\n",
      "2024-05-28 11:38:28,835 [INFO ]    - On récupère les matchs du 18/10/2023\n",
      "2024-05-28 11:38:31,189 [INFO ]    - On récupère les matchs du 19/10/2023\n",
      "2024-05-28 11:38:33,222 [INFO ]    - On récupère les matchs du 20/10/2023\n",
      "2024-05-28 11:38:35,627 [INFO ]    - On récupère les matchs du 21/10/2023\n",
      "2024-05-28 11:38:37,691 [INFO ]    - On récupère les matchs du 22/10/2023\n",
      "2024-05-28 11:38:39,964 [INFO ]    - On récupère les matchs du 23/10/2023\n",
      "2024-05-28 11:38:41,925 [INFO ]    - On récupère les matchs du 24/10/2023\n",
      "2024-05-28 11:38:44,287 [INFO ]    - On récupère les matchs du 25/10/2023\n",
      "2024-05-28 11:38:46,753 [INFO ]    - On récupère les matchs du 26/10/2023\n",
      "2024-05-28 11:38:48,754 [INFO ]    - On récupère les matchs du 27/10/2023\n",
      "2024-05-28 11:38:50,874 [INFO ]    - On récupère les matchs du 28/10/2023\n",
      "2024-05-28 11:38:53,430 [INFO ]    - On récupère les matchs du 29/10/2023\n",
      "2024-05-28 11:38:55,324 [INFO ]    - On récupère les matchs du 30/10/2023\n",
      "2024-05-28 11:38:57,344 [INFO ]    - On récupère les matchs du 31/10/2023\n",
      "2024-05-28 11:38:59,784 [INFO ]    - On récupère les matchs du 01/11/2023\n",
      "2024-05-28 11:39:01,885 [INFO ]    - On récupère les matchs du 02/11/2023\n",
      "2024-05-28 11:39:04,485 [INFO ]    - On récupère les matchs du 03/11/2023\n",
      "2024-05-28 11:39:06,129 [INFO ]    - On récupère les matchs du 04/11/2023\n",
      "2024-05-28 11:39:07,970 [INFO ]    - On récupère les matchs du 05/11/2023\n",
      "2024-05-28 11:39:09,900 [INFO ]    - On récupère les matchs du 06/11/2023\n",
      "2024-05-28 11:39:11,782 [INFO ]    - On récupère les matchs du 07/11/2023\n",
      "2024-05-28 11:39:17,079 [INFO ]    - On récupère les matchs du 08/11/2023\n",
      "2024-05-28 11:39:18,821 [INFO ]    - On récupère les matchs du 09/11/2023\n",
      "2024-05-28 11:39:21,101 [INFO ]    - On récupère les matchs du 10/11/2023\n",
      "2024-05-28 11:39:22,379 [INFO ]    - On récupère les matchs du 11/11/2023\n",
      "2024-05-28 11:39:23,912 [INFO ]    - On récupère les matchs du 12/11/2023\n",
      "2024-05-28 11:39:25,196 [INFO ]    - On récupère les matchs du 13/11/2023\n",
      "2024-05-28 11:39:26,576 [INFO ]    - On récupère les matchs du 14/11/2023\n",
      "2024-05-28 11:39:27,929 [INFO ]    - On récupère les matchs du 15/11/2023\n",
      "2024-05-28 11:39:29,440 [INFO ]    - On récupère les matchs du 16/11/2023\n",
      "2024-05-28 11:39:31,085 [INFO ]    - On récupère les matchs du 17/11/2023\n",
      "2024-05-28 11:39:32,373 [INFO ]    - On récupère les matchs du 18/11/2023\n",
      "2024-05-28 11:39:33,706 [INFO ]    - On récupère les matchs du 19/11/2023\n",
      "2024-05-28 11:39:35,624 [INFO ]    - On récupère les matchs du 20/11/2023\n",
      "2024-05-28 11:39:37,119 [INFO ]    - On récupère les matchs du 21/11/2023\n",
      "2024-05-28 11:39:38,540 [INFO ]    - On récupère les matchs du 22/11/2023\n",
      "2024-05-28 11:39:39,790 [INFO ]    - On récupère les matchs du 23/11/2023\n",
      "2024-05-28 11:39:41,703 [INFO ]    - On récupère les matchs du 24/11/2023\n",
      "2024-05-28 11:39:43,112 [INFO ]    - On récupère les matchs du 25/11/2023\n",
      "2024-05-28 11:39:45,318 [INFO ]    - On récupère les matchs du 26/11/2023\n",
      "2024-05-28 11:39:47,157 [INFO ]    - On récupère les matchs du 27/11/2023\n",
      "2024-05-28 11:39:49,137 [INFO ]    - On récupère les matchs du 28/11/2023\n",
      "2024-05-28 11:39:52,347 [INFO ]    - On récupère les matchs du 29/11/2023\n",
      "2024-05-28 11:39:55,370 [INFO ]    - On récupère les matchs du 30/11/2023\n",
      "2024-05-28 11:39:57,172 [INFO ]    - On récupère les matchs du 01/12/2023\n",
      "2024-05-28 11:39:58,717 [INFO ]    - On récupère les matchs du 02/12/2023\n",
      "2024-05-28 11:40:00,450 [INFO ]    - On récupère les matchs du 03/12/2023\n",
      "2024-05-28 11:40:03,534 [INFO ]    - On récupère les matchs du 04/12/2023\n",
      "2024-05-28 11:40:05,700 [INFO ]    - On récupère les matchs du 05/12/2023\n",
      "2024-05-28 11:40:08,830 [INFO ]    - On récupère les matchs du 06/12/2023\n",
      "2024-05-28 11:40:10,994 [INFO ]    - On récupère les matchs du 07/12/2023\n",
      "2024-05-28 11:40:13,272 [INFO ]    - On récupère les matchs du 08/12/2023\n",
      "2024-05-28 11:40:15,286 [INFO ]    - On récupère les matchs du 09/12/2023\n",
      "2024-05-28 11:40:17,965 [INFO ]    - On récupère les matchs du 10/12/2023\n",
      "2024-05-28 11:40:20,200 [INFO ]    - On récupère les matchs du 11/12/2023\n",
      "2024-05-28 11:40:22,583 [INFO ]    - On récupère les matchs du 12/12/2023\n",
      "2024-05-28 11:40:24,499 [INFO ]    - On récupère les matchs du 13/12/2023\n",
      "2024-05-28 11:40:26,693 [INFO ]    - On récupère les matchs du 14/12/2023\n",
      "2024-05-28 11:40:28,599 [INFO ]    - On récupère les matchs du 15/12/2023\n",
      "2024-05-28 11:40:29,884 [INFO ]    - On récupère les matchs du 16/12/2023\n",
      "2024-05-28 11:40:32,102 [INFO ]    - On récupère les matchs du 17/12/2023\n",
      "2024-05-28 11:40:34,063 [INFO ]    - On récupère les matchs du 18/12/2023\n",
      "2024-05-28 11:40:35,595 [INFO ]    - On récupère les matchs du 19/12/2023\n",
      "2024-05-28 11:40:37,151 [INFO ]    - On récupère les matchs du 20/12/2023\n",
      "2024-05-28 11:40:39,196 [INFO ]    - On récupère les matchs du 21/12/2023\n",
      "2024-05-28 11:40:41,744 [INFO ]    - On récupère les matchs du 22/12/2023\n",
      "2024-05-28 11:40:43,092 [INFO ]    - On récupère les matchs du 23/12/2023\n",
      "2024-05-28 11:40:45,125 [INFO ]    - On récupère les matchs du 24/12/2023\n",
      "2024-05-28 11:40:46,949 [INFO ]    - On récupère les matchs du 25/12/2023\n",
      "2024-05-28 11:40:49,151 [INFO ]    - On récupère les matchs du 26/12/2023\n",
      "2024-05-28 11:40:51,317 [INFO ]    - On récupère les matchs du 27/12/2023\n",
      "2024-05-28 11:40:53,267 [INFO ]    - On récupère les matchs du 28/12/2023\n",
      "2024-05-28 11:40:55,375 [INFO ]    - On récupère les matchs du 29/12/2023\n",
      "2024-05-28 11:40:57,550 [INFO ]    - On récupère les matchs du 30/12/2023\n",
      "2024-05-28 11:40:59,475 [INFO ]    - On récupère les matchs du 31/12/2023\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "current_date = dt.datetime.strptime(\"2023-08-20\", \"%Y-%m-%d\")\n",
    "# current_date = START\n",
    "matches = []\n",
    "competitions = []\n",
    "matches_df = pd.DataFrame()\n",
    "CM = pd.DataFrame()\n",
    "while current_date <= STOP_DATA:\n",
    "    logger.info(f\"  - On récupère les matchs du {current_date.strftime('%d/%m/%Y')}\")\n",
    "    # Initialize lists to store match and competition information\n",
    "\n",
    "    r = requests.get(f\"https://www.footendirect.com/football/international/?selectedDate={current_date.strftime('%Y-%m-%d')}\")\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    # Find the table containing the matches\n",
    "    res = soup.find('table', {'class': \"table matches table-condensed layout-fixed linked-rows\"})\n",
    "\n",
    "    # Find all rows in the table\n",
    "    rows = res.findAll(\"tr\")\n",
    "\n",
    "    # Initialize variable to keep track of current competition\n",
    "    current_competition = None\n",
    "\n",
    "    # Process each row\n",
    "    for row in rows:\n",
    "        # Check if the row represents a competition badge\n",
    "        if \"competition-badge\" in row.get(\"id\", \"\"):\n",
    "            competition_link = row.find(\"a\", href=True)\n",
    "            if competition_link:\n",
    "                current_competition = competition_link.text.strip()\n",
    "                competitions.append(current_competition)\n",
    "        else:\n",
    "\n",
    "            if row.get(\"class\") and \"league-data\" in row.get(\"class\") and \"league-data-heading\" not in row.get(\"class\"):\n",
    "                current_competition = row.find(\"div\", class_=\"title\").text.strip().split('\\n')[1].strip()\n",
    "                competitions.append(current_competition)\n",
    "\n",
    "            # Check if the row represents a match\n",
    "            match_data = row.find(\"td\", class_=\"teams\")\n",
    "            if match_data:\n",
    "                match_date = row[\"data-date\"].split(\" \")[0]\n",
    "                match_time = row.find(\"td\", class_=\"hour\").text.strip()\n",
    "                match_teams = match_data.findAll(\"a\")\n",
    "                match_teams = [team.text.strip() for team in match_teams][0]\n",
    "\n",
    "                matches.append({\"Date\": match_date, \"Time\": match_time, \"Competition\": current_competition, \"Teams\": match_teams})\n",
    "\n",
    "    matches_of_day = pd.DataFrame(matches)\n",
    "    # Create DataFrame for matches\n",
    "    matches_df = pd.concat([matches_df, matches_of_day])\n",
    "\n",
    "    # # Print matches and competitions\n",
    "    # print(\"Matches:\")\n",
    "    # print(matches_df)\n",
    "    # print(\"\\nCompetitions:\")\n",
    "    # print(competitions)\n",
    "    if len(matches_of_day) > 0:\n",
    "        CM = pd.concat([CM, pd.DataFrame([len(matches_of_day)], index=[current_date])], axis=0)\n",
    "    current_date += dt.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df.to_csv('matches4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_df = pd.DataFrame()\n",
    "for i in range(1, 5):\n",
    "    matches_loaded = pd.read_csv(f\"matches{i}.csv\", index_col=0)\n",
    "    loaded_df = pd.concat([loaded_df, matches_loaded])\n",
    "loaded_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_df['Date'] = pd.to_datetime(loaded_df['Date'])\n",
    "result_df = loaded_df.pivot_table(index='Date', columns='Competition', aggfunc='size', fill_value=0)\n",
    "all_dates = pd.date_range(START, STOP_DATA)\n",
    "result_df = result_df.reindex(all_dates, fill_value=0)\n",
    "\n",
    "# Réinitialiser l'index pour obtenir un DataFrame\n",
    "result_df = result_df.reset_index().rename(columns={'index': 'date_entree'})\n",
    "\n",
    "result_df.set_index('date_entree', inplace=True)\n",
    "\n",
    "\n",
    "result_df.to_csv('INTERNATIONAL.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
